{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10905eef",
   "metadata": {},
   "source": [
    "# Stock Price Prediction with GRU\n",
    "\n",
    "This notebook focuses specifically on stock price time series forecasting using **GRU (Gated Recurrent Unit)** networks.\n",
    "\n",
    "## Overview\n",
    "\n",
    "- **Task**: Stock price prediction using historical OHLCV data\n",
    "- **Model**: GRU-based RNN with technical indicators\n",
    "- **Data**: Synthetic stock data with realistic patterns\n",
    "- **Goal**: Build an effective stock price forecasting model\n",
    "\n",
    "## Key Features\n",
    "\n",
    "1. **Realistic Synthetic Data**: OHLCV data with trends, volatility, and patterns\n",
    "2. **Technical Indicators**: Moving averages, volatility measures\n",
    "3. **GRU Architecture**: Optimized for financial time series\n",
    "4. **Comprehensive Evaluation**: Multiple metrics and visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2d55fd",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06e650cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n",
      "TensorFlow version: 2.20.0\n",
      "Focus: Stock Price Prediction with GRU\n"
     ]
    }
   ],
   "source": [
    "# Core libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Deep Learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Focus: Stock Price Prediction with GRU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f26866",
   "metadata": {},
   "source": [
    "## 2. Generate Stock Data with Technical Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5b0641e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating stock data...\n",
      "Generated 1200 days of stock data\n",
      "Date range: 2020-01-01 00:00:00 to 2023-04-14 00:00:00\n",
      "Price range: $78.23 - $402.56\n",
      "Features: ['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'MA_5', 'MA_10', 'MA_20', 'Returns', 'Price_Change', 'Volatility_5', 'Volatility_10', 'HL_Range', 'OC_Range', 'Volume_MA', 'Volume_Ratio']\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>MA_5</th>\n",
       "      <th>MA_10</th>\n",
       "      <th>MA_20</th>\n",
       "      <th>Returns</th>\n",
       "      <th>Price_Change</th>\n",
       "      <th>Volatility_5</th>\n",
       "      <th>Volatility_10</th>\n",
       "      <th>HL_Range</th>\n",
       "      <th>OC_Range</th>\n",
       "      <th>Volume_MA</th>\n",
       "      <th>Volume_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>100.00</td>\n",
       "      <td>100.13</td>\n",
       "      <td>99.87</td>\n",
       "      <td>100.00</td>\n",
       "      <td>914118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>100.06</td>\n",
       "      <td>100.60</td>\n",
       "      <td>99.23</td>\n",
       "      <td>99.77</td>\n",
       "      <td>1009772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.002300</td>\n",
       "      <td>-0.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013732</td>\n",
       "      <td>-0.002898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>99.79</td>\n",
       "      <td>101.83</td>\n",
       "      <td>99.09</td>\n",
       "      <td>101.12</td>\n",
       "      <td>867419</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013531</td>\n",
       "      <td>1.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027097</td>\n",
       "      <td>0.013328</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>100.41</td>\n",
       "      <td>106.07</td>\n",
       "      <td>98.65</td>\n",
       "      <td>104.25</td>\n",
       "      <td>751227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030953</td>\n",
       "      <td>3.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.071175</td>\n",
       "      <td>0.038243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>103.89</td>\n",
       "      <td>104.63</td>\n",
       "      <td>103.06</td>\n",
       "      <td>103.81</td>\n",
       "      <td>1178984</td>\n",
       "      <td>101.79</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.004221</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015124</td>\n",
       "      <td>-0.000770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date    Open    High     Low   Close   Volume    MA_5  MA_10  MA_20  \\\n",
       "0 2020-01-01  100.00  100.13   99.87  100.00   914118     NaN    NaN    NaN   \n",
       "1 2020-01-02  100.06  100.60   99.23   99.77  1009772     NaN    NaN    NaN   \n",
       "2 2020-01-03   99.79  101.83   99.09  101.12   867419     NaN    NaN    NaN   \n",
       "3 2020-01-04  100.41  106.07   98.65  104.25   751227     NaN    NaN    NaN   \n",
       "4 2020-01-05  103.89  104.63  103.06  103.81  1178984  101.79    NaN    NaN   \n",
       "\n",
       "    Returns  Price_Change  Volatility_5  Volatility_10  HL_Range  OC_Range  \\\n",
       "0       NaN           NaN           NaN            NaN  0.002600  0.000000   \n",
       "1 -0.002300         -0.23           NaN            NaN  0.013732 -0.002898   \n",
       "2  0.013531          1.35           NaN            NaN  0.027097  0.013328   \n",
       "3  0.030953          3.13           NaN            NaN  0.071175  0.038243   \n",
       "4 -0.004221         -0.44           NaN            NaN  0.015124 -0.000770   \n",
       "\n",
       "   Volume_MA  Volume_Ratio  \n",
       "0        NaN           NaN  \n",
       "1        NaN           NaN  \n",
       "2        NaN           NaN  \n",
       "3        NaN           NaN  \n",
       "4        NaN           NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_stock_data(n_days=1000, start_price=100.0, volatility=0.02):\n",
    "    \"\"\"Generate synthetic stock price data with realistic patterns.\"\"\"\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Generate dates\n",
    "    start_date = datetime(2020, 1, 1)\n",
    "    dates = [start_date + timedelta(days=i) for i in range(n_days)]\n",
    "    \n",
    "    # Generate price data using geometric Brownian motion\n",
    "    returns = np.random.normal(0.0005, volatility, n_days)  # Small positive drift\n",
    "    prices = [start_price]\n",
    "    \n",
    "    for i in range(1, n_days):\n",
    "        price = prices[-1] * (1 + returns[i])\n",
    "        prices.append(max(price, 1.0))  # Prevent negative prices\n",
    "    \n",
    "    # Generate OHLC data\n",
    "    data = []\n",
    "    for i, (date, close) in enumerate(zip(dates, prices)):\n",
    "        # Open price (close to previous close)\n",
    "        if i == 0:\n",
    "            open_price = close\n",
    "        else:\n",
    "            open_price = prices[i-1] * (1 + np.random.normal(0, volatility/4))\n",
    "        \n",
    "        # High and low prices\n",
    "        daily_range = abs(np.random.normal(0, volatility/2))\n",
    "        high = max(open_price, close) * (1 + daily_range)\n",
    "        low = min(open_price, close) * (1 - daily_range)\n",
    "        \n",
    "        # Volume\n",
    "        volume = int(np.random.normal(1000000, 200000))\n",
    "        volume = max(volume, 100000)\n",
    "        \n",
    "        data.append({\n",
    "            'Date': date,\n",
    "            'Open': round(open_price, 2),\n",
    "            'High': round(high, 2),\n",
    "            'Low': round(low, 2),\n",
    "            'Close': round(close, 2),\n",
    "            'Volume': volume\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "def add_technical_indicators(df):\n",
    "    \"\"\"Add technical indicators to stock data.\"\"\"\n",
    "    # Moving averages\n",
    "    df['MA_5'] = df['Close'].rolling(window=5).mean()\n",
    "    df['MA_10'] = df['Close'].rolling(window=10).mean()\n",
    "    df['MA_20'] = df['Close'].rolling(window=20).mean()\n",
    "    \n",
    "    # Price changes\n",
    "    df['Returns'] = df['Close'].pct_change()\n",
    "    df['Price_Change'] = df['Close'].diff()\n",
    "    \n",
    "    # Volatility measures\n",
    "    df['Volatility_5'] = df['Returns'].rolling(window=5).std()\n",
    "    df['Volatility_10'] = df['Returns'].rolling(window=10).std()\n",
    "    \n",
    "    # High-Low measures\n",
    "    df['HL_Range'] = (df['High'] - df['Low']) / df['Close']\n",
    "    df['OC_Range'] = (df['Close'] - df['Open']) / df['Open']\n",
    "    \n",
    "    # Volume indicators\n",
    "    df['Volume_MA'] = df['Volume'].rolling(window=10).mean()\n",
    "    df['Volume_Ratio'] = df['Volume'] / df['Volume_MA']\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate and enhance stock data\n",
    "print(\"Generating stock data...\")\n",
    "stock_df = generate_stock_data(n_days=1200)\n",
    "stock_df = add_technical_indicators(stock_df)\n",
    "\n",
    "print(f\"Generated {len(stock_df)} days of stock data\")\n",
    "print(f\"Date range: {stock_df['Date'].min()} to {stock_df['Date'].max()}\")\n",
    "print(f\"Price range: ${stock_df['Close'].min():.2f} - ${stock_df['Close'].max():.2f}\")\n",
    "print(f\"Features: {list(stock_df.columns)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "stock_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3433c2d6",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Sequence Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81e854f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using features: ['Open', 'High', 'Low', 'Close', 'Volume', 'MA_5', 'MA_10', 'MA_20', 'Volatility_5', 'Volatility_10', 'HL_Range', 'OC_Range', 'Volume_Ratio']\n",
      "Data shape after cleaning: (1181, 13)\n",
      "Stock data preparation complete!\n",
      "Training sequences: (784, 60, 13)\n",
      "Validation sequences: (168, 60, 13)\n",
      "Test sequences: (169, 60, 13)\n",
      "Features used: 13\n",
      "\n",
      "Data integrity check:\n",
      "No NaN in training data: True\n",
      "Data range: [0.000, 1.000]\n",
      "Stock data preparation complete!\n",
      "Training sequences: (784, 60, 13)\n",
      "Validation sequences: (168, 60, 13)\n",
      "Test sequences: (169, 60, 13)\n",
      "Features used: 13\n",
      "\n",
      "Data integrity check:\n",
      "No NaN in training data: True\n",
      "Data range: [0.000, 1.000]\n"
     ]
    }
   ],
   "source": [
    "def prepare_stock_sequences(data, sequence_length=60, target_col='Close'):\n",
    "    \"\"\"Prepare stock data for RNN training.\"\"\"\n",
    "    # Select numerical features only and remove NaN values\n",
    "    feature_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'MA_5', 'MA_10', 'MA_20', \n",
    "                   'Volatility_5', 'Volatility_10', 'HL_Range', 'OC_Range', 'Volume_Ratio']\n",
    "    \n",
    "    # Remove columns with too many NaN values or use available features\n",
    "    available_cols = [col for col in feature_cols if col in data.columns]\n",
    "    df = data[available_cols].dropna()\n",
    "    \n",
    "    print(f\"Using features: {available_cols}\")\n",
    "    print(f\"Data shape after cleaning: {df.shape}\")\n",
    "    \n",
    "    # Scale the data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(df)\n",
    "    \n",
    "    # Find target column index\n",
    "    target_idx = available_cols.index(target_col)\n",
    "    \n",
    "    # Create sequences\n",
    "    X, y = [], []\n",
    "    for i in range(sequence_length, len(scaled_data)):\n",
    "        X.append(scaled_data[i-sequence_length:i])\n",
    "        y.append(scaled_data[i, target_idx])\n",
    "    \n",
    "    X, y = np.array(X), np.array(y)\n",
    "    \n",
    "    # Split into train, validation, and test\n",
    "    train_size = int(0.7 * len(X))\n",
    "    val_size = int(0.85 * len(X))\n",
    "    \n",
    "    X_train = X[:train_size]\n",
    "    y_train = y[:train_size]\n",
    "    X_val = X[train_size:val_size]\n",
    "    y_val = y[train_size:val_size]\n",
    "    X_test = X[val_size:]\n",
    "    y_test = y[val_size:]\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test, scaler, available_cols\n",
    "\n",
    "# Prepare stock data\n",
    "SEQUENCE_LENGTH = 60\n",
    "X_train, X_val, X_test, y_train, y_val, y_test, scaler, features = prepare_stock_sequences(\n",
    "    stock_df, sequence_length=SEQUENCE_LENGTH\n",
    ")\n",
    "\n",
    "print(\"Stock data preparation complete!\")\n",
    "print(f\"Training sequences: {X_train.shape}\")\n",
    "print(f\"Validation sequences: {X_val.shape}\")\n",
    "print(f\"Test sequences: {X_test.shape}\")\n",
    "print(f\"Features used: {len(features)}\")\n",
    "\n",
    "# Verify data integrity\n",
    "print(f\"\\nData integrity check:\")\n",
    "print(f\"No NaN in training data: {not np.isnan(X_train).any()}\")\n",
    "print(f\"Data range: [{X_train.min():.3f}, {X_train.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e65969",
   "metadata": {},
   "source": [
    "## 4. Build Optimized GRU Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "180cfdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized GRU model created!\n",
      "Input shape: (60, 13)\n",
      "Total parameters: 28,641\n",
      "\n",
      "Model architecture:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">15,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m15,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_2 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │         \u001b[38;5;34m9,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m32\u001b[0m)         │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ gru_3 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m2,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m64\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,641</span> (111.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m28,641\u001b[0m (111.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,353</span> (110.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m28,353\u001b[0m (110.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">288</span> (1.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m288\u001b[0m (1.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_optimized_gru_model(input_shape, units=[64, 32, 16], dropout_rate=0.3):\n",
    "    \"\"\"Create an optimized GRU model for stock prediction.\"\"\"\n",
    "    model = Sequential([\n",
    "        # First GRU layer\n",
    "        GRU(units=units[0], return_sequences=True, input_shape=input_shape, \n",
    "            dropout=dropout_rate, recurrent_dropout=dropout_rate, name='gru_1'),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        # Second GRU layer\n",
    "        GRU(units=units[1], return_sequences=True,\n",
    "            dropout=dropout_rate, recurrent_dropout=dropout_rate, name='gru_2'),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        # Third GRU layer\n",
    "        GRU(units=units[2], return_sequences=False,\n",
    "            dropout=dropout_rate, recurrent_dropout=dropout_rate, name='gru_3'),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        # Dense layers with regularization\n",
    "        Dense(units=32, activation='relu', name='dense_1'),\n",
    "        Dropout(dropout_rate),\n",
    "        BatchNormalization(),\n",
    "        \n",
    "        Dense(units=16, activation='relu', name='dense_2'),\n",
    "        Dropout(dropout_rate/2),\n",
    "        \n",
    "        # Output layer\n",
    "        Dense(units=1, activation='linear', name='output')\n",
    "    ])\n",
    "    \n",
    "    # Compile with optimized settings\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001, clipnorm=1.0),\n",
    "        loss='huber',  # More robust to outliers\n",
    "        metrics=['mae', 'mse']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "model = create_optimized_gru_model(input_shape)\n",
    "\n",
    "print(\"Optimized GRU model created!\")\n",
    "print(f\"Input shape: {input_shape}\")\n",
    "print(f\"Total parameters: {model.count_params():,}\")\n",
    "print(\"\\nModel architecture:\")\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
